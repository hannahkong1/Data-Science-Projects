{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 6, 7, 8, 9, 11, 20, 24, 25, 27, 29, 30, 32, 34, 36, 37, 38, 40]\n",
      "[10, 13, 14, 15, 16, 17, 19, 31, 35, 39]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Step 1: Load Metadata\n",
    "meta_data = pd.read_csv(\"metadata.csv\")  # Adjust this path to your metadata file's location\n",
    "# Step 2: Identify participants\n",
    "# Participants who only know English\n",
    "only_english = meta_data[meta_data[['spanish', 'german', 'french']].sum(axis=1) == 0]['participant'].tolist()\n",
    "print(only_english)\n",
    "# Participants who know English and Spanish\n",
    "bilingual_spanish = meta_data[meta_data['spanish'] == 1]['participant'].tolist()\n",
    "print(bilingual_spanish)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Speakers: Average electrode values for the word 'book' (English-English):\n",
      "Fpz   -8.851778e-17\n",
      "Fp2   -1.541560e-16\n",
      "F7     5.785537e-17\n",
      "F3    -1.294010e-17\n",
      "Fz    -1.950392e-17\n",
      "F4     5.401085e-17\n",
      "F8    -4.997879e-17\n",
      "FC5    3.570248e-17\n",
      "FC1    5.251055e-18\n",
      "FC2    1.500301e-17\n",
      "FC6    6.938894e-18\n",
      "T7    -9.095577e-18\n",
      "C3     3.563216e-17\n",
      "Cz    -4.163336e-17\n",
      "C4    -1.500301e-18\n",
      "T8    -6.882633e-17\n",
      "CP5    1.125226e-17\n",
      "CP1    4.500904e-18\n",
      "CP2   -4.688442e-17\n",
      "CP6   -7.651537e-17\n",
      "P7    -1.305262e-16\n",
      "P3     1.697216e-17\n",
      "Pz    -4.425889e-17\n",
      "P4    -4.454020e-17\n",
      "P8     7.876582e-17\n",
      "POz    4.050814e-17\n",
      "O1     2.775558e-17\n",
      "Oz    -8.645487e-17\n",
      "O2    -5.269809e-17\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Filter participants who know only English (all zeros)\n",
    "only_english_participants = metadata[metadata[['spanish', 'german', 'french']].sum(axis=1) == 0]\n",
    "\n",
    "# Create a list to store DataFrames\n",
    "book_english_english_dataframes = []\n",
    "\n",
    "# Loop through files and collect data for participants who know only English\n",
    "for file in os.listdir(path):\n",
    "    # Check for files related to the word \"book\" and English-English translation\n",
    "    if \"book\" in file and \"english-english\" in file:\n",
    "        # Extract the participant ID from the filename\n",
    "        participant_id = file.split('_')[-1].split('.')[0]\n",
    "        \n",
    "        # Check if the participant is in the only English group\n",
    "        if participant_id in only_english_participants['participant'].astype(str).values:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(os.path.join(path, file))\n",
    "            book_english_english_dataframes.append(df)\n",
    "\n",
    "# Create a list to store DataFrames\n",
    "book_spanish_english_dataframes = []\n",
    "\n",
    "#Repeat for Spanish-English\n",
    "for file in os.listdir(path):\n",
    "    if \"book\" in file and \"spanish-english\" in file:\n",
    "        participant_id = file.split('_')[-1].split('.')[0]\n",
    "        if participant_id in only_english_participants['participant'].astype(str).values:\n",
    "            df = pd.read_csv(os.path.join(path, file))\n",
    "            book_spanish_english_dataframes.append(df)\n",
    "#Averaging\n",
    "            \n",
    "if book_english_english_dataframes:\n",
    "    # Step 2: Combine all DataFrames into one\n",
    "    combined_df = pd.concat(book_english_english_dataframes, ignore_index=True)\n",
    "\n",
    "    # Step 3: Calculate the average for each electrode\n",
    "    # Assuming all electrode columns are prefixed with a certain pattern\n",
    "    # You can also explicitly define the columns if you know them\n",
    "    electrode_columns = combined_df.columns[1:] \n",
    "    # Step 4: Calculate the average for each electrode\n",
    "    electrode_averages = combined_df[electrode_columns].mean(axis=0)  # Mean across all rows for each column\n",
    "    # Print the average electrode values\n",
    "    print(\"English Speakers: Average electrode values for the word 'book' (English-English):\")\n",
    "    print(electrode_averages)\n",
    "else:\n",
    "    print(\"No DataFrames available for averaging.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Speakers: Average electrode values for the word 'book' (Spanish-English):\n",
      "Fpz    9.038822e-18\n",
      "Fp2   -1.563077e-16\n",
      "F7     4.181597e-17\n",
      "F3     1.234393e-16\n",
      "Fz    -1.075529e-16\n",
      "F4     6.591949e-17\n",
      "F8     9.988355e-17\n",
      "FC5   -3.816392e-17\n",
      "FC1    8.965781e-17\n",
      "FC2   -1.427951e-16\n",
      "FC6   -2.118189e-16\n",
      "T7     9.230555e-17\n",
      "C3    -1.186916e-16\n",
      "Cz     2.684256e-17\n",
      "C4     1.625162e-16\n",
      "T8     1.633379e-16\n",
      "CP5    7.326924e-17\n",
      "CP1    1.360388e-17\n",
      "CP2    8.071029e-17\n",
      "CP6   -1.208828e-16\n",
      "P7    -4.921137e-17\n",
      "P3     1.044486e-16\n",
      "Pz     8.344933e-17\n",
      "P4     6.646730e-17\n",
      "P8    -7.559742e-17\n",
      "POz    7.596263e-17\n",
      "O1    -3.542488e-17\n",
      "Oz     8.071029e-17\n",
      "O2    -6.911504e-17\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot merge a Series without a name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo DataFrames available for averaging.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m merged_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(electrode_averages, meta_data, on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mparticipant\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Convert categorical target variable to numeric\u001b[39;00m\n\u001b[1;32m     17\u001b[0m merged_data[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m merged_data[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap({\u001b[39m'\u001b[39m\u001b[39mEnglish-English\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSpanish-English\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m})\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/merge.py:148\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m--> 148\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    149\u001b[0m         left,\n\u001b[1;32m    150\u001b[0m         right,\n\u001b[1;32m    151\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m    152\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m    153\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m    154\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m    155\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m    156\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m    157\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    158\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m    159\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m    160\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    162\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/merge.py:680\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    665\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    666\u001b[0m     left: DataFrame \u001b[39m|\u001b[39m Series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    678\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    679\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m     _left \u001b[39m=\u001b[39m _validate_operand(left)\n\u001b[1;32m    681\u001b[0m     _right \u001b[39m=\u001b[39m _validate_operand(right)\n\u001b[1;32m    682\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_left \u001b[39m=\u001b[39m _left\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/merge.py:2572\u001b[0m, in \u001b[0;36m_validate_operand\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2570\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, ABCSeries):\n\u001b[1;32m   2571\u001b[0m     \u001b[39mif\u001b[39;00m obj\u001b[39m.\u001b[39mname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2572\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot merge a Series without a name\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2573\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   2574\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot merge a Series without a name"
     ]
    }
   ],
   "source": [
    "#Averaging for Spanish-English\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "if book_spanish_english_dataframes:\n",
    "    combined_df = pd.concat(book_spanish_english_dataframes, ignore_index=True)\n",
    "    electrode_columns = combined_df.columns[1:]\n",
    "    electrode_averages = combined_df[electrode_columns].mean(axis=0)  \n",
    "    print(\"English Speakers: Average electrode values for the word 'book' (Spanish-English):\")\n",
    "    print(electrode_averages)\n",
    "else:\n",
    "    print(\"No DataFrames available for averaging.\")\n",
    "\n",
    "merged_data = pd.merge(electrode_averages, meta_data, on='participant')\n",
    "\n",
    "# Convert categorical target variable to numeric\n",
    "merged_data['target'] = merged_data['target'].map({'English-English': 0, 'Spanish-English': 1})\n",
    "\n",
    "# Define features (EEG and language background) and target\n",
    "X = merged_data.drop(columns=['participant', 'target'])\n",
    "y = merged_data['target']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now for spanish bilingual speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish Speakers: Average electrode values for the word 'book' (English-English):\n",
      "Fpz   -1.869849e-16\n",
      "Fp2    1.168656e-16\n",
      "F7     7.011935e-17\n",
      "F3    -9.349247e-17\n",
      "Fz    -1.869849e-16\n",
      "F4     9.349247e-17\n",
      "F8     8.180591e-17\n",
      "FC5   -1.636118e-16\n",
      "FC1    9.349247e-17\n",
      "FC2   -7.011935e-17\n",
      "FC6   -5.843279e-17\n",
      "T7     4.674623e-17\n",
      "C3    -1.869849e-16\n",
      "Cz    -7.011935e-17\n",
      "C4    -9.349247e-17\n",
      "T8    -2.921640e-17\n",
      "CP5   -7.596263e-17\n",
      "CP1   -4.674623e-17\n",
      "CP2   -1.519253e-16\n",
      "CP6   -4.674623e-17\n",
      "P7    -1.168656e-17\n",
      "P3     4.674623e-17\n",
      "Pz     8.764919e-17\n",
      "P4     1.519253e-16\n",
      "P8    -8.180591e-17\n",
      "POz    1.168656e-16\n",
      "O1     2.337312e-17\n",
      "Oz    -3.272236e-16\n",
      "O2     0.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bilingual_participants = meta_data[meta_data['spanish'] == 1]\n",
    "\n",
    "s_book_english_english_dataframes = []\n",
    "#English-English\n",
    "for file in os.listdir(path):\n",
    "    if \"book\" in file and \"english-english\" in file:\n",
    "        participant_id = file.split('_')[-1].split('.')[0]\n",
    "        if participant_id in bilingual_participants['participant'].astype(str).values:\n",
    "            df = pd.read_csv(os.path.join(path, file))\n",
    "            s_book_english_english_dataframes.append(df)\n",
    "\n",
    "s_book_spanish_english_dataframes = []\n",
    "\n",
    "#Spanish-English\n",
    "for file in os.listdir(path):\n",
    "    if \"book\" in file and \"spanish-english\" in file:\n",
    "        participant_id = file.split('_')[-1].split('.')[0]\n",
    "        if participant_id in bilingual_participants['participant'].astype(str).values:\n",
    "            df = pd.read_csv(os.path.join(path, file))\n",
    "            s_book_spanish_english_dataframes.append(df)\n",
    "#English-English\n",
    "if s_book_english_english_dataframes:\n",
    "    combined_df = pd.concat(s_book_english_english_dataframes, ignore_index=True)\n",
    "    electrode_columns = combined_df.columns[1:]  \n",
    "    electrode_averages = combined_df[electrode_columns].mean(axis=0) \n",
    "    print(\"Spanish Speakers: Average electrode values for the word 'book' (English-English):\")\n",
    "    print(electrode_averages)\n",
    "else:\n",
    "    print(\"No DataFrames available for averaging.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish Speakers: Average electrode values for the word 'book' (Spanish-English):\n",
      "Fpz   -1.402387e-16\n",
      "Fp2    5.843279e-17\n",
      "F7    -4.674623e-17\n",
      "F3     5.843279e-17\n",
      "Fz     1.402387e-16\n",
      "F4     1.402387e-16\n",
      "F8     9.349247e-17\n",
      "FC5    7.011935e-17\n",
      "FC1   -2.337312e-17\n",
      "FC2   -1.636118e-16\n",
      "FC6   -1.402387e-16\n",
      "T7    -9.349247e-17\n",
      "C3    -2.337312e-17\n",
      "Cz     4.674623e-17\n",
      "C4    -4.674623e-17\n",
      "T8     1.402387e-16\n",
      "CP5   -1.051790e-16\n",
      "CP1   -9.349247e-17\n",
      "CP2    1.519253e-16\n",
      "CP6   -3.505967e-17\n",
      "P7     1.168656e-16\n",
      "P3     5.843279e-17\n",
      "Pz     2.337312e-17\n",
      "P4     2.337312e-17\n",
      "P8     2.337312e-17\n",
      "POz    4.674623e-17\n",
      "O1     4.674623e-17\n",
      "Oz    -1.051790e-16\n",
      "O2     7.011935e-17\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Spanish-English\n",
    "if s_book_spanish_english_dataframes:\n",
    "    combined_df = pd.concat(s_book_spanish_english_dataframes, ignore_index=True)\n",
    "    electrode_columns = combined_df.columns[1:]  \n",
    "    electrode_averages = combined_df[electrode_columns].mean(axis=0) \n",
    "    print(\"Spanish Speakers: Average electrode values for the word 'book' (Spanish-English):\")\n",
    "    print(electrode_averages)\n",
    "else:\n",
    "    print(\"No DataFrames available for averaging.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
